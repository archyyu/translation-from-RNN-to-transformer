{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archyyu/translation-from-RNN-to-transformer/blob/main/machine_translation_by_rnn_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAzMVzsKlJlV",
        "outputId": "92fd3af3-e404-4542-a97a-f55f687b5898"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79573d38c2b0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dKvwvE3qUB3q"
      },
      "outputs": [],
      "source": [
        "hidden_size = 100\n",
        "embedding_dim = 30\n",
        "learning_rate = 0.001\n",
        "batch_size = 50\n",
        "beam_width = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pgaJy39hUt2C"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/archyyu/publicResource/main/eng-fra.txt\"\n",
        "response = requests.get(url)\n",
        "lines = response.text.split('\\n')\n",
        "en_lines = []\n",
        "fr_lines = []\n",
        "\n",
        "start_character = '<'\n",
        "end_character = '>'\n",
        "padding_character = '&'\n",
        "\n",
        "for i in range(2000,3000):\n",
        "  item = lines[i].split('\\t')\n",
        "  en_lines.append(item[0] + '>')\n",
        "  fr_lines.append('<' + item[1] + '>')\n",
        "\n",
        "max_len_line_en = max([len(l) for l in en_lines])\n",
        "max_len_line_fr = max([len(l) for l in fr_lines])\n",
        "\n",
        "for i in range(len(en_lines)):\n",
        "  if (len(en_lines[i]) < max_len_line_en):\n",
        "    en_lines[i] = en_lines[i].ljust(max_len_line_en, padding_character)\n",
        "  if (len(fr_lines[i]) < max_len_line_fr):\n",
        "    fr_lines[i] = fr_lines[i].ljust(max_len_line_fr, padding_character)\n",
        "\n",
        "\n",
        "source_vocab = sorted(set(''.join(en_lines)))\n",
        "target_vocab = sorted(set(''.join(fr_lines)))\n",
        "\n",
        "source_vocab_size = len(set(''.join(source_vocab)))\n",
        "target_vocab_size = len(set(''.join(target_vocab)))\n",
        "\n",
        "source_char_to_ix = {ch: i for i, ch in enumerate(source_vocab)}\n",
        "source_ix_to_char = {i: ch for i, ch in enumerate(source_vocab)}\n",
        "\n",
        "target_char_to_ix = {ch: i for i, ch in enumerate(target_vocab)}\n",
        "target_ix_to_char = {i: ch for i, ch in enumerate(target_vocab)}\n",
        "\n",
        "padding_token_index = target_char_to_ix[padding_character]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GUfLKgxoU7j3"
      },
      "outputs": [],
      "source": [
        "def line_to_tensor(line):\n",
        "  result = []\n",
        "  line_ten = torch.tensor([source_char_to_ix[ch] for ch in test_line], dtype=torch.long).view(1, -1)\n",
        "  result.append(line_ten)\n",
        "  return torch.cat(result, dim=0)\n",
        "\n",
        "def target_line_to_tensor(line):\n",
        "  result = []\n",
        "  line_ten = torch.tensor([target_char_to_ix[ch] for ch in test_line], dtype=torch.long).view(1, -1)\n",
        "  result.append(line_ten)\n",
        "  return torch.cat(result, dim=0)\n",
        "\n",
        "en_data = []\n",
        "fr_data = []\n",
        "for i in range(len(en_lines)):\n",
        "  e = torch.tensor([source_char_to_ix[ch] for ch in en_lines[i]], dtype=torch.long).view(1, -1)\n",
        "  en_data.append(e)\n",
        "  f = torch.tensor([target_char_to_ix[ch] for ch in fr_lines[i]], dtype=torch.long).view(1, -1)\n",
        "  fr_data.append(f)\n",
        "\n",
        "en_data = torch.cat(en_data, dim=0)\n",
        "fr_data = torch.cat(fr_data, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_aiwNJdMpOvb"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "    self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
        "    self.v = nn.Parameter(torch.rand(hidden_size))\n",
        "\n",
        "  def forward(self, hidden, encoder_outputs):\n",
        "    seq_len = encoder_outputs.size(1)\n",
        "    # Repeat the hidden state for all timesteps\n",
        "    hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "    # Concatenate the hidden state and encoder outputs\n",
        "    energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=-1)))\n",
        "    # Calculate attention scores\n",
        "    attention_scores = torch.matmul(energy, self.v)\n",
        "    # Convert attention scores to probabilities\n",
        "    attention_weights = torch.softmax(attention_scores, dim=1)\n",
        "    # Calculate the attention-weighted sum of encoder outputs\n",
        "    context_vector = torch.sum(attention_weights.unsqueeze(2) * encoder_outputs, dim=1)\n",
        "    return context_vector\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.i2h = nn.Linear(embedding_dim, hidden_size, bias=False)\n",
        "    self.h2h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "    self.hb2 = nn.Parameter(torch.zeros(1, hidden_size))\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = torch.zeros(1, self.hidden_size)\n",
        "    h_list = []\n",
        "    for i in range(x.shape[1]):\n",
        "      t = self.embedding(x[:,i])\n",
        "      h = torch.tanh(self.i2h(t) + self.h2h(h) + self.hb2)\n",
        "      h_list.append(h)\n",
        "    return torch.stack(h_list, dim=0)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.embedding = nn.Embedding(vocab_size, self.embedding_dim)\n",
        "    self.i2h = nn.Linear(self.embedding_dim, self.hidden_size, bias=False)\n",
        "    self.h2h = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "    self.h2o = nn.Linear(self.hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    self.e2d = nn.Linear(self.hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    self.hb2 = nn.Parameter(torch.zeros(1, self.hidden_size))\n",
        "    self.ob = nn.Parameter(torch.zeros(1, vocab_size))\n",
        "\n",
        "    self.att = Attention(hidden_size)\n",
        "\n",
        "  def init_state(self, encode_state):\n",
        "    T,B,C = encode_state.shape\n",
        "    self.encode_state = encode_state.reshape(B,T,C)\n",
        "\n",
        "\n",
        "  def forward(self, batch_size):\n",
        "\n",
        "    # if x is None:\n",
        "    h = torch.zeros(batch_size, self.hidden_size)\n",
        "    x = torch.tensor([target_char_to_ix[start_character] for _ in range(batch_size)],dtype=torch.long)\n",
        "    output = []\n",
        "    for i in range(max_len_line_fr):\n",
        "      t = self.embedding(x)\n",
        "      h = torch.tanh(self.i2h(t) + self.h2h(h) + self.hb2)\n",
        "      context_state = self.att(h, self.encode_state)\n",
        "      y = self.e2d(context_state) + self.h2o(h) + self.ob\n",
        "      p = nn.functional.softmax(y, dim=1)\n",
        "      ix = torch.argmax(p, dim=-1)\n",
        "      x = ix\n",
        "      output.append(y)\n",
        "    return torch.stack(output, dim=0).permute(1, 0, 2)\n",
        "\n",
        "  def beam_search(self):\n",
        "    \"\"\"\n",
        "    Perform beam search to generate sequences.\n",
        "    \"\"\"\n",
        "    beams = [(torch.tensor([target_char_to_ix[start_character]], dtype=torch.long), 1.0)]\n",
        "    h = torch.zeros(1, self.hidden_size)\n",
        "\n",
        "    for i in range(max_len_line_fr):\n",
        "      new_beams = []\n",
        "\n",
        "      for seq, score in beams:\n",
        "        x = seq[-1].view(1, -1)  # Take the last predicted token\n",
        "\n",
        "        t = self.embedding(x)\n",
        "        h = torch.tanh(self.i2h(t) + self.h2h(h) + self.hb2)\n",
        "        context_state = self.att(h.reshape(-1, self.hidden_size), self.encode_state)\n",
        "        y = self.e2d(context_state) + self.h2o(h) + self.ob\n",
        "        p = F.softmax(y, dim=-1)\n",
        "        top_probs, top_ix = torch.topk(p, beam_width, dim=-1)\n",
        "\n",
        "        for prob, token_ix in zip(top_probs[0][0], top_ix[0][0]):\n",
        "          new_seq = torch.cat((seq, torch.tensor([token_ix], dtype=torch.long)), dim=0)\n",
        "          new_beams.append((new_seq, score * prob.item()))\n",
        "\n",
        "      beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "\n",
        "    return beams\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, source_vocab_size, target_vocab_size, embedding_dim, hidden_size):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_size = hidden_size\n",
        "    self.encoder = Encoder(source_vocab_size, self.embedding_dim, self.hidden_size)\n",
        "    self.decoder = Decoder(target_vocab_size, self.embedding_dim, self.hidden_size)\n",
        "  def forward(self, source, batch_size):\n",
        "    hidden_state = self.encoder(source)\n",
        "    self.decoder.init_state(hidden_state)\n",
        "    output = self.decoder(batch_size)\n",
        "    return output\n",
        "\n",
        "  def translate(self, source):\n",
        "    hidden_state = self.encoder(source)\n",
        "    self.decoder.init_state(hidden_state)\n",
        "    beams = self.decoder.beam_search()\n",
        "    return beams\n",
        "\n",
        "\n",
        "# Define your model, loss function, and optimizer\n",
        "model = Seq2Seq(source_vocab_size, target_vocab_size, embedding_dim, hidden_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "1HwqI27qRs9_",
        "outputId": "f3902778-7384-4cc5-dfbd-afe9cad83f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p 0, Loss: 0.912079930305481\n",
            "p 100, Loss: 0.9531503915786743\n",
            "p 200, Loss: 1.029158592224121\n",
            "p 300, Loss: 0.7917560338973999\n",
            "p 400, Loss: 0.834060788154602\n",
            "p 500, Loss: 0.7916983962059021\n",
            "p 600, Loss: 0.7827950716018677\n",
            "p 700, Loss: 1.1014405488967896\n",
            "p 800, Loss: 1.0037251710891724\n",
            "p 900, Loss: 0.9997793436050415\n",
            "p 0, Loss: 0.924619197845459\n",
            "p 100, Loss: 0.9614687561988831\n",
            "p 200, Loss: 1.0369371175765991\n",
            "p 300, Loss: 0.7861080765724182\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-24dd25037151>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpadding_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#training\n",
        "import torch.optim as optim\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "  for p in range(len(en_data) - batch_size - 1):\n",
        "\n",
        "    source_batch = en_data[p:p+batch_size]\n",
        "    target_batch = fr_data[p:p+batch_size]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    # encoder = Encoder(source_vocab_size, embedding_dim, hidden_size)\n",
        "    # output = encoder(source_batch)\n",
        "    output = model(source_batch, batch_size)\n",
        "\n",
        "    output = output.reshape(-1, target_vocab_size)\n",
        "    # remove the padding tokens when calculate the loss\n",
        "    # Create a mask to ignore padding tokens\n",
        "    padding_mask = (target_batch != padding_token_index).float()\n",
        "\n",
        "    # Compute the loss with the padding mask\n",
        "    loss = criterion(output, target_batch.view(-1))\n",
        "    loss = (loss * padding_mask.view(-1)).sum() / padding_mask.sum()\n",
        "\n",
        "    loss.backward()\n",
        "    for param in model.parameters():\n",
        "      if param.grad is not None:\n",
        "        param.grad.data.clamp_(-5, 5)\n",
        "    optimizer.step()\n",
        "\n",
        "    if p%100 == 0:\n",
        "      # Print or log the training loss for each epoch\n",
        "      print(f'p {p}, Loss: {loss.item()}')\n",
        "\n",
        "    p += batch_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxVVtitSdL6t",
        "outputId": "c9656fe1-7289-4038-9d85-fef79b6fdedb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<Nn   s&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "<<Nn  o &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "<<Nn o &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n"
          ]
        }
      ],
      "source": [
        "test_line = \"I cut myself>\"\n",
        "\n",
        "input = line_to_tensor(test_line)\n",
        "\n",
        "outputs = model.translate(input)\n",
        "for tensor,p in outputs:\n",
        "  result = [target_ix_to_char[j.item()] for j in tensor]\n",
        "  print(''.join(result))\n",
        "\n",
        "# outputs = model(input,1)\n",
        "# result = []\n",
        "# for i in range(outputs.shape[0]):\n",
        "\n",
        "#   p = nn.functional.softmax(outputs[i], dim=-1).detach().numpy().ravel()\n",
        "#   ix = np.random.choice(range(target_vocab_size), p=p)\n",
        "\n",
        "#   result.append(target_ix_to_char[ix])\n",
        "\n",
        "# print(''.join(result))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hhu-SBOUE-6",
        "outputId": "09806306-3a9d-425c-9b59-3570233c56bc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I'm chicken.>&\",\n",
              " \"I'm chicken.>&\",\n",
              " \"I'm correct.>&\",\n",
              " \"I'm curious.>&\",\n",
              " \"I'm curious.>&\",\n",
              " \"I'm dancing.>&\",\n",
              " \"I'm dieting.>&\",\n",
              " \"I'm driving.>&\",\n",
              " \"I'm driving.>&\",\n",
              " \"I'm engaged.>&\",\n",
              " \"I'm engaged.>&\",\n",
              " \"I'm excited.>&\",\n",
              " \"I'm excited.>&\",\n",
              " \"I'm fasting.>&\",\n",
              " \"I'm fasting.>&\",\n",
              " \"I'm finicky.>&\",\n",
              " \"I'm finicky.>&\",\n",
              " \"I'm frantic.>&\",\n",
              " \"I'm frantic.>&\",\n",
              " \"I'm furious.>&\",\n",
              " \"I'm healthy.>&\",\n",
              " \"I'm humming.>&\",\n",
              " \"I'm in luck.>&\",\n",
              " \"I'm in luck.>&\",\n",
              " \"I'm jealous.>&\",\n",
              " \"I'm jittery.>&\",\n",
              " \"I'm kidding.>&\",\n",
              " \"I'm kidding.>&\",\n",
              " \"I'm leaving.>&\",\n",
              " \"I'm married.>&\",\n",
              " \"I'm married.>&\",\n",
              " \"I'm no fool.>&\",\n",
              " \"I'm no hero.>&\",\n",
              " \"I'm no liar.>&\",\n",
              " \"I'm not fat.>&\",\n",
              " \"I'm not mad.>&\",\n",
              " \"I'm not mad.>&\",\n",
              " \"I'm not old.>&\",\n",
              " \"I'm not old.>&\",\n",
              " \"I'm not sad.>&\",\n",
              " \"I'm not shy.>&\",\n",
              " \"I'm on duty.>&\",\n",
              " \"I'm patient.>&\",\n",
              " \"I'm patient.>&\",\n",
              " \"I'm popular.>&\",\n",
              " \"I'm psyched.>&\",\n",
              " \"I'm psychic.>&\",\n",
              " \"I'm psychic.>&\",\n",
              " \"I'm puzzled.>&\",\n",
              " \"I'm reading.>&\",\n",
              " \"I'm relaxed.>&\",\n",
              " \"I'm relaxed.>&\",\n",
              " \"I'm retired.>&\",\n",
              " \"I'm retired.>&\",\n",
              " \"I'm retired.>&\",\n",
              " \"I'm retired.>&\",\n",
              " \"I'm selfish.>&\",\n",
              " \"I'm serious.>&\",\n",
              " \"I'm shocked.>&\",\n",
              " \"I'm shocked.>&\",\n",
              " \"I'm sincere.>&\",\n",
              " \"I'm sloshed.>&\",\n",
              " \"I'm sloshed.>&\",\n",
              " \"I'm so full.>&\",\n",
              " \"I'm starved.>&\",\n",
              " \"I'm starved.>&\",\n",
              " \"I'm starved.>&\",\n",
              " \"I'm starved.>&\",\n",
              " \"I'm staying.>&\",\n",
              " \"I'm stuffed.>&\",\n",
              " \"I'm stuffed.>&\",\n",
              " \"I'm stunned.>&\",\n",
              " \"I'm stunned.>&\",\n",
              " \"I'm talking.>&\",\n",
              " \"I'm teasing.>&\",\n",
              " \"I'm thirsty.>&\",\n",
              " \"I'm through.>&\",\n",
              " \"I'm through.>&\",\n",
              " \"I'm too fat.>&\",\n",
              " \"I'm touched.>&\",\n",
              " \"I'm touched.>&\",\n",
              " \"I'm unhappy.>&\",\n",
              " \"I'm unhappy.>&\",\n",
              " \"I'm unlucky.>&\",\n",
              " \"I'm wealthy.>&\",\n",
              " \"I'm wealthy.>&\",\n",
              " \"I'm winning.>&\",\n",
              " \"I'm winning.>&\",\n",
              " \"I'm working.>&\",\n",
              " \"I'm worried.>&\",\n",
              " \"I've failed.>&\",\n",
              " 'Ignore them.>&',\n",
              " 'Ignore them.>&',\n",
              " 'Is Tom sure?>&',\n",
              " 'Is he right?>&',\n",
              " 'Is it clean?>&',\n",
              " 'Is it clear?>&',\n",
              " 'Is it dirty?>&',\n",
              " 'Is it fatal?>&',\n",
              " 'Is it legal?>&',\n",
              " 'Is it ready?>&',\n",
              " 'Is it to go?>&',\n",
              " 'Is it to go?>&',\n",
              " 'Is it to go?>&',\n",
              " 'Is it yours?>&',\n",
              " 'Is it yours?>&',\n",
              " 'Is it yours?>&',\n",
              " 'Is it yours?>&',\n",
              " 'Is it yours?>&',\n",
              " 'Is it yours?>&',\n",
              " 'Is it yours?>&',\n",
              " 'Is she gone?>&',\n",
              " 'Is that all?>&',\n",
              " 'Is that you?>&',\n",
              " 'Is that you?>&',\n",
              " 'Is that you?>&',\n",
              " \"It can't be!>&\",\n",
              " 'It is foggy.>&',\n",
              " 'It may snow.>&',\n",
              " 'It was long.>&',\n",
              " \"It's 50 yen.>&\",\n",
              " \"It's Monday.>&\",\n",
              " \"It's a doll.>&\",\n",
              " \"It's a song.>&\",\n",
              " \"It's all OK.>&\",\n",
              " \"It's all OK.>&\",\n",
              " \"It's broken.>&\",\n",
              " \"It's cloudy.>&\",\n",
              " \"It's ironic.>&\",\n",
              " \"It's locked.>&\",\n",
              " \"It's my job.>&\",\n",
              " \"It's my job.>&\",\n",
              " \"It's my son.>&\",\n",
              " \"It's no use.>&\",\n",
              " \"It's not us.>&\",\n",
              " \"It's poison.>&\",\n",
              " \"It's secret.>&\",\n",
              " \"It's silent.>&\",\n",
              " \"It's stupid.>&\",\n",
              " \"It's urgent.>&\",\n",
              " \"It's warmer.>&\",\n",
              " \"It's warmer.>&\",\n",
              " 'Just say no.>&',\n",
              " 'Just say no.>&',\n",
              " 'Keep trying.>&',\n",
              " 'Keep trying.>&',\n",
              " 'Keep trying.>&',\n",
              " 'Keep trying.>&',\n",
              " 'Let me help.>&',\n",
              " 'Let me help.>&',\n",
              " 'Let me know.>&',\n",
              " 'Let me know.>&',\n",
              " 'Let me talk.>&',\n",
              " 'Let me talk.>&',\n",
              " \"Let's begin.>&\",\n",
              " \"Let's dance.>&\",\n",
              " \"Let's do it!>&\",\n",
              " \"Let's do it!>&\",\n",
              " \"Let's do it!>&\",\n",
              " \"Let's do it!>&\",\n",
              " \"Let's do it.>&\",\n",
              " \"Let's drink.>&\",\n",
              " \"Let's hurry.>&\",\n",
              " \"Let's split.>&\",\n",
              " \"Let's split.>&\",\n",
              " \"Let's start!>&\",\n",
              " 'Life is fun.>&',\n",
              " 'Look around.>&',\n",
              " 'Look around.>&',\n",
              " 'Lunch is on.>&',\n",
              " 'Make a list.>&',\n",
              " 'Make a list.>&',\n",
              " 'Make a wish.>&',\n",
              " 'Make a wish.>&',\n",
              " 'Many thanks.>&',\n",
              " 'Many thanks.>&',\n",
              " 'Many thanks.>&',\n",
              " 'Many thanks.>&',\n",
              " 'May I begin?>&',\n",
              " 'Money talks.>&',\n",
              " 'Need a lift?>&',\n",
              " 'Nice timing.>&',\n",
              " 'Nice timing.>&',\n",
              " 'Nice timing.>&',\n",
              " 'Nice timing.>&',\n",
              " 'Nice timing.>&',\n",
              " 'No means no.>&',\n",
              " 'No one came.>&',\n",
              " 'No one came.>&',\n",
              " 'No one died.>&',\n",
              " 'No one left.>&',\n",
              " 'No one left.>&',\n",
              " 'Nobody came.>&',\n",
              " 'Nobody came.>&',\n",
              " 'Nobody died.>&',\n",
              " \"Now I'm sad.>&\",\n",
              " 'Now we wait.>&',\n",
              " 'OK. I agree.>&',\n",
              " 'Oh, come on.>&',\n",
              " 'Pick a card.>&',\n",
              " 'Pick a card.>&',\n",
              " 'Pick a date.>&',\n",
              " 'Pick a date.>&',\n",
              " 'Plants grow.>&',\n",
              " 'Plants grow.>&',\n",
              " 'Please come.>&',\n",
              " 'Please come.>&',\n",
              " 'Please come.>&',\n",
              " 'Please come.>&',\n",
              " 'Please sing.>&',\n",
              " 'Please sing.>&',\n",
              " 'Please sing.>&',\n",
              " 'Please sing.>&',\n",
              " 'Please sing.>&',\n",
              " 'Please stop.>&',\n",
              " 'Please stop.>&',\n",
              " 'Please stop.>&',\n",
              " 'Please stop.>&',\n",
              " 'Please stop.>&',\n",
              " 'Please stop.>&',\n",
              " 'Put it back.>&',\n",
              " 'Put it down.>&',\n",
              " 'Put it down.>&',\n",
              " 'Release him.>&',\n",
              " 'Release him.>&',\n",
              " 'Remember it.>&',\n",
              " 'Remember it.>&',\n",
              " 'Send him in.>&',\n",
              " 'Send him in.>&',\n",
              " 'Shall we go?>&',\n",
              " 'She blushed.>&',\n",
              " 'She fainted.>&',\n",
              " 'She hit him.>&',\n",
              " 'She hit him.>&',\n",
              " 'She is curt.>&',\n",
              " 'She is dead.>&',\n",
              " 'She is kind.>&',\n",
              " 'She is late.>&',\n",
              " 'She woke up.>&',\n",
              " \"She's a dog.>&\",\n",
              " \"She's a fox.>&\",\n",
              " 'Should I go?>&',\n",
              " 'Should I go?>&',\n",
              " 'Sleep tight.>&',\n",
              " 'Sleep tight.>&',\n",
              " 'Stand aside.>&',\n",
              " 'Stand aside.>&',\n",
              " 'Stand aside.>&',\n",
              " 'Stand aside.>&',\n",
              " 'Stay in bed.>&',\n",
              " 'Stay in bed.>&',\n",
              " 'Stay in bed.>&',\n",
              " 'Stay in bed.>&',\n",
              " 'Stay in bed.>&',\n",
              " 'Stay in bed.>&',\n",
              " 'Stay in bed.>&',\n",
              " 'Stay in bed.>&',\n",
              " 'Step inside.>&',\n",
              " 'Step inside.>&',\n",
              " 'Stop crying.>&',\n",
              " 'Stop crying.>&',\n",
              " 'Stop trying.>&',\n",
              " 'Take a bite.>&',\n",
              " 'Take a bite.>&',\n",
              " 'Take a bite.>&',\n",
              " 'Take a bite.>&',\n",
              " 'Take a card.>&',\n",
              " 'Take a card.>&',\n",
              " 'Take a look.>&',\n",
              " 'Take a look.>&',\n",
              " 'Take a look.>&',\n",
              " 'Take a look.>&',\n",
              " 'Take a rest.>&',\n",
              " 'Take a rest.>&',\n",
              " 'Take a seat.>&',\n",
              " 'Take a seat.>&',\n",
              " 'Take a seat.>&',\n",
              " 'Take a seat.>&',\n",
              " 'Take a walk.>&',\n",
              " 'Take a walk.>&',\n",
              " 'Take it all.>&',\n",
              " 'Take it all.>&',\n",
              " 'That is all.>&',\n",
              " 'That worked.>&',\n",
              " 'That worked.>&',\n",
              " \"That's cool.>&\",\n",
              " \"That's cool.>&\",\n",
              " \"That's hers.>&\",\n",
              " \"That's hers.>&\",\n",
              " \"That's hers.>&\",\n",
              " \"That's hers.>&\",\n",
              " \"That's icky.>&\",\n",
              " \"That's icky.>&\",\n",
              " \"That's lame.>&\",\n",
              " \"That's lame.>&\",\n",
              " \"That's mine.>&\",\n",
              " \"That's mine.>&\",\n",
              " \"That's true.>&\",\n",
              " \"That's true.>&\",\n",
              " \"That's ugly.>&\",\n",
              " \"That's wise.>&\",\n",
              " \"The TV's on.>&\",\n",
              " 'There he is.>&',\n",
              " 'There he is.>&',\n",
              " 'There it is.>&',\n",
              " 'They burned.>&',\n",
              " 'They burned.>&',\n",
              " 'They got it.>&',\n",
              " 'They got it.>&',\n",
              " 'They hugged.>&',\n",
              " 'They hugged.>&',\n",
              " 'They obeyed.>&',\n",
              " 'They obeyed.>&',\n",
              " 'They smiled.>&',\n",
              " 'They smiled.>&',\n",
              " \"They're bad.>&\",\n",
              " \"They're bad.>&\",\n",
              " \"They're old.>&\",\n",
              " \"They're old.>&\",\n",
              " 'This is bad.>&',\n",
              " 'This is bad.>&',\n",
              " 'This is bad.>&',\n",
              " 'This is bad.>&',\n",
              " 'This is big.>&',\n",
              " 'This is big.>&',\n",
              " 'This is fun.>&',\n",
              " 'This is his.>&',\n",
              " 'This is his.>&',\n",
              " 'This is new.>&',\n",
              " 'This is new.>&',\n",
              " 'This is odd.>&',\n",
              " 'This stinks.>&',\n",
              " 'Tom blinked.>&',\n",
              " 'Tom drowned.>&',\n",
              " 'Tom drowned.>&',\n",
              " 'Tom is dead.>&',\n",
              " 'Tom is nuts.>&',\n",
              " 'Tom is weak.>&',\n",
              " 'Tom laughed.>&',\n",
              " 'Tom left me.>&',\n",
              " 'Tom left me.>&',\n",
              " 'Tom listens.>&',\n",
              " \"Tom'll quit.>&\",\n",
              " \"Tom'll quit.>&\",\n",
              " \"Tom's alive.>&\",\n",
              " \"Tom's alive.>&\",\n",
              " \"Tom's alone.>&\",\n",
              " \"Tom's alone.>&\",\n",
              " \"Tom's bored.>&\",\n",
              " \"Tom's funny.>&\",\n",
              " \"Tom's funny.>&\",\n",
              " \"Tom's funny.>&\",\n",
              " \"Tom's lying.>&\",\n",
              " \"Tom's sorry.>&\",\n",
              " 'Turn around.>&',\n",
              " 'Turn around.>&',\n",
              " 'Turn it off.>&',\n",
              " 'Turn it off.>&',\n",
              " 'Wait for us.>&',\n",
              " 'Wait for us.>&',\n",
              " 'Wake Tom up.>&',\n",
              " 'War is evil.>&',\n",
              " 'War is hell.>&',\n",
              " 'Was I wrong?>&',\n",
              " 'Was I wrong?>&',\n",
              " 'Was I wrong?>&',\n",
              " 'We all know.>&',\n",
              " 'We all know.>&',\n",
              " 'We all quit.>&',\n",
              " 'We all quit.>&',\n",
              " 'We all quit.>&',\n",
              " 'We all quit.>&',\n",
              " 'We all work.>&',\n",
              " 'We all work.>&',\n",
              " 'We are even.>&',\n",
              " 'We are even.>&',\n",
              " 'We are here.>&',\n",
              " 'We are here.>&',\n",
              " 'We are late.>&',\n",
              " 'We broke up.>&',\n",
              " 'We broke up.>&',\n",
              " 'We broke up.>&',\n",
              " 'We broke up.>&',\n",
              " 'We broke up.>&',\n",
              " 'We broke up.>&',\n",
              " 'We can meet.>&',\n",
              " 'We can talk.>&',\n",
              " 'We can wait.>&',\n",
              " \"We can't go.>&\",\n",
              " \"We can't go.>&\",\n",
              " \"We can't go.>&\",\n",
              " \"We can't go.>&\",\n",
              " \"We can't go.>&\",\n",
              " 'We did fine.>&',\n",
              " 'We did fine.>&',\n",
              " 'We did that.>&',\n",
              " 'We did that.>&',\n",
              " 'We found it.>&',\n",
              " 'We know him.>&',\n",
              " 'We know him.>&',\n",
              " 'We like Tom.>&',\n",
              " 'We like Tom.>&',\n",
              " 'We like Tom.>&',\n",
              " 'We like him.>&',\n",
              " 'We like him.>&',\n",
              " 'We miss you.>&',\n",
              " 'We miss you.>&',\n",
              " 'We must act.>&',\n",
              " 'We must run.>&',\n",
              " 'We must try.>&',\n",
              " 'We need Tom.>&',\n",
              " 'We promised.>&',\n",
              " 'We promised.>&',\n",
              " 'We remember.>&',\n",
              " 'We remember.>&',\n",
              " 'We survived!>&',\n",
              " 'We survived.>&',\n",
              " 'We survived.>&',\n",
              " 'We want Tom.>&',\n",
              " \"We'll check.>&\",\n",
              " \"We'll dance.>&\",\n",
              " \"We'll drive.>&\",\n",
              " \"We'll fight.>&\",\n",
              " \"We'll hurry.>&\",\n",
              " \"We'll share.>&\",\n",
              " \"We'll shoot.>&\",\n",
              " \"We'll stand.>&\",\n",
              " \"We'll start.>&\",\n",
              " \"We're alone.>&\",\n",
              " \"We're alone.>&\",\n",
              " \"We're angry.>&\",\n",
              " \"We're armed.>&\",\n",
              " \"We're armed.>&\",\n",
              " \"We're bored.>&\",\n",
              " \"We're bored.>&\",\n",
              " \"We're broke.>&\",\n",
              " \"We're broke.>&\",\n",
              " \"We're broke.>&\",\n",
              " \"We're dying.>&\",\n",
              " \"We're early.>&\",\n",
              " \"We're going.>&\",\n",
              " \"We're happy.>&\",\n",
              " \"We're ready.>&\",\n",
              " \"We're saved.>&\",\n",
              " \"We're saved.>&\",\n",
              " \"We're smart.>&\",\n",
              " \"We're smart.>&\",\n",
              " \"We're sorry.>&\",\n",
              " \"We're sorry.>&\",\n",
              " \"We're stuck.>&\",\n",
              " \"We're stuck.>&\",\n",
              " \"We're tired.>&\",\n",
              " \"We're tired.>&\",\n",
              " \"We're twins.>&\",\n",
              " \"We're twins.>&\",\n",
              " 'What a bore!>&',\n",
              " 'What a bore!>&',\n",
              " 'What a dope!>&',\n",
              " 'What a dope!>&',\n",
              " 'What a drag!>&',\n",
              " 'What a dump.>&',\n",
              " 'What a heel!>&',\n",
              " 'What a jerk!>&',\n",
              " 'What a joke!>&',\n",
              " 'What a loss!>&',\n",
              " 'What a mess!>&',\n",
              " 'What a mess!>&',\n",
              " 'What a pain!>&',\n",
              " 'What a pity!>&',\n",
              " 'What a pity!>&',\n",
              " 'What a team!>&',\n",
              " 'What is art?>&',\n",
              " 'What was it?>&',\n",
              " 'What was it?>&',\n",
              " 'What was it?>&',\n",
              " 'What was it?>&',\n",
              " \"What'd I do?>&\",\n",
              " \"What's that?>&\",\n",
              " \"What's that?>&\",\n",
              " \"What's that?>&\",\n",
              " \"What's that?>&\",\n",
              " \"What's this?>&\",\n",
              " \"What's this?>&\",\n",
              " \"What's this?>&\",\n",
              " 'Where is he?>&',\n",
              " 'Where was I?>&',\n",
              " 'Where was I?>&',\n",
              " 'Who are you?>&',\n",
              " 'Who are you?>&',\n",
              " 'Who is next?>&',\n",
              " \"Who's going?>&\",\n",
              " \"Who's there?>&\",\n",
              " 'Whose is it?>&',\n",
              " 'Will it fit?>&',\n",
              " 'Will it fit?>&',\n",
              " 'Will it fit?>&',\n",
              " 'Will you go?>&',\n",
              " 'Will you go?>&',\n",
              " 'Will you go?>&',\n",
              " 'Will you go?>&',\n",
              " 'Work slowly.>&',\n",
              " 'Work slowly.>&',\n",
              " 'You are big.>&',\n",
              " 'You are big.>&',\n",
              " 'You are big.>&',\n",
              " 'You are big.>&',\n",
              " 'You are big.>&',\n",
              " 'You are big.>&',\n",
              " 'You are mad.>&',\n",
              " 'You cheated.>&',\n",
              " 'You cheated.>&',\n",
              " 'You fainted.>&',\n",
              " 'You fainted.>&',\n",
              " 'You hurt me.>&',\n",
              " 'You hurt me.>&',\n",
              " 'You may sit.>&',\n",
              " 'You may sit.>&',\n",
              " 'You must go.>&',\n",
              " 'You must go.>&',\n",
              " 'You must go.>&',\n",
              " 'You must go.>&',\n",
              " \"You're back.>&\",\n",
              " \"You're back.>&\",\n",
              " \"You're cool.>&\",\n",
              " \"You're cool.>&\",\n",
              " \"You're fair.>&\",\n",
              " \"You're fair.>&\",\n",
              " \"You're fair.>&\",\n",
              " \"You're fine.>&\",\n",
              " \"You're free.>&\",\n",
              " \"You're free.>&\",\n",
              " \"You're free.>&\",\n",
              " \"You're good.>&\",\n",
              " \"You're good.>&\",\n",
              " \"You're good.>&\",\n",
              " \"You're good.>&\",\n",
              " \"You're good.>&\",\n",
              " \"You're good.>&\",\n",
              " \"You're good.>&\",\n",
              " \"You're good.>&\",\n",
              " \"You're kind.>&\",\n",
              " \"You're kind.>&\",\n",
              " \"You're lazy.>&\",\n",
              " \"You're lazy.>&\",\n",
              " \"You're lazy.>&\",\n",
              " \"You're lazy.>&\",\n",
              " \"You're lazy.>&\",\n",
              " \"You're lost.>&\",\n",
              " \"You're lost.>&\",\n",
              " \"You're nice.>&\",\n",
              " \"You're nice.>&\",\n",
              " \"You're nice.>&\",\n",
              " \"You're nuts!>&\",\n",
              " \"You're nuts!>&\",\n",
              " \"You're nuts!>&\",\n",
              " \"You're nuts!>&\",\n",
              " \"You're nuts!>&\",\n",
              " \"You're nuts!>&\",\n",
              " \"You're nuts!>&\",\n",
              " \"You're nuts!>&\",\n",
              " \"You're nuts!>&\",\n",
              " \"You're nuts!>&\",\n",
              " \"You're rich.>&\",\n",
              " \"You're rich.>&\",\n",
              " \"You're rich.>&\",\n",
              " \"You're rude.>&\",\n",
              " \"You're rude.>&\",\n",
              " \"You're rude.>&\",\n",
              " \"You're rude.>&\",\n",
              " \"You're rude.>&\",\n",
              " \"You're safe.>&\",\n",
              " \"You're safe.>&\",\n",
              " \"You're safe.>&\",\n",
              " \"You're safe.>&\",\n",
              " \"You're safe.>&\",\n",
              " \"You're safe.>&\",\n",
              " \"You're safe.>&\",\n",
              " \"You're safe.>&\",\n",
              " \"You're sick!>&\",\n",
              " \"You're sick!>&\",\n",
              " \"You're sick!>&\",\n",
              " \"You're thin.>&\",\n",
              " \"You're thin.>&\",\n",
              " \"You're thin.>&\",\n",
              " \"You're weak.>&\",\n",
              " \"You're weak.>&\",\n",
              " \"You're weak.>&\",\n",
              " 'Abandon ship!>',\n",
              " 'All is quiet.>',\n",
              " 'All is still.>',\n",
              " 'Am I correct?>',\n",
              " 'Anybody here?>',\n",
              " 'Anybody here?>',\n",
              " 'Anybody home?>',\n",
              " 'Anybody home?>',\n",
              " 'Anybody home?>',\n",
              " 'Anybody hurt?>',\n",
              " 'Anybody hurt?>',\n",
              " 'Anything new?>',\n",
              " 'Are we alone?>',\n",
              " 'Are we alone?>',\n",
              " 'Are we broke?>',\n",
              " 'Are we broke?>',\n",
              " 'Are we ready?>',\n",
              " 'Are we ready?>',\n",
              " 'Are you bald?>',\n",
              " 'Are you bald?>',\n",
              " 'Are you bald?>',\n",
              " 'Are you busy?>',\n",
              " 'Are you busy?>',\n",
              " 'Are you busy?>',\n",
              " 'Are you busy?>',\n",
              " 'Are you busy?>',\n",
              " 'Are you busy?>',\n",
              " 'Are you busy?>',\n",
              " 'Are you deaf?>',\n",
              " 'Are you deaf?>',\n",
              " 'Are you deaf?>',\n",
              " 'Are you deaf?>',\n",
              " 'Are you home?>',\n",
              " 'Are you home?>',\n",
              " 'Are you home?>',\n",
              " 'Are you home?>',\n",
              " 'Are you home?>',\n",
              " 'Are you home?>',\n",
              " 'Are you home?>',\n",
              " 'Are you home?>',\n",
              " 'Are you hurt?>',\n",
              " 'Are you hurt?>',\n",
              " 'Are you hurt?>',\n",
              " 'Are you hurt?>',\n",
              " 'Are you hurt?>',\n",
              " 'Are you hurt?>',\n",
              " 'Are you hurt?>',\n",
              " 'Are you hurt?>',\n",
              " 'Are you hurt?>',\n",
              " 'Are you hurt?>',\n",
              " 'Are you lost?>',\n",
              " 'Are you lost?>',\n",
              " 'Are you lost?>',\n",
              " 'Are you lost?>',\n",
              " 'Are you lost?>',\n",
              " 'Are you lost?>',\n",
              " 'Are you sick?>',\n",
              " 'Are you sure?>',\n",
              " 'Are you sure?>',\n",
              " 'Are you sure?>',\n",
              " 'Are you sure?>',\n",
              " 'Are you sure?>',\n",
              " 'Are you sure?>',\n",
              " 'Are you sure?>',\n",
              " 'Are you sure?>',\n",
              " 'Are you sure?>',\n",
              " 'Are you sure?>',\n",
              " 'Be attentive.>',\n",
              " 'Be attentive.>',\n",
              " 'Be confident.>',\n",
              " 'Be confident.>',\n",
              " 'Be confident.>',\n",
              " 'Be confident.>',\n",
              " 'Be confident.>',\n",
              " 'Be confident.>',\n",
              " 'Beef, please.>',\n",
              " 'Beef, please.>',\n",
              " 'Bring a date.>',\n",
              " 'Bring him in.>',\n",
              " 'Can I go now?>',\n",
              " 'Can I go now?>',\n",
              " 'Can I go now?>',\n",
              " 'Can I try it?>',\n",
              " 'Can he do it?>',\n",
              " 'Can he do it?>',\n",
              " 'Can we leave?>',\n",
              " 'Can we leave?>',\n",
              " 'Can we start?>',\n",
              " 'Can you come?>',\n",
              " 'Can you come?>',\n",
              " 'Can you stay?>',\n",
              " 'Can you swim?>',\n",
              " 'Can you swim?>',\n",
              " 'Can you swim?>',\n",
              " 'Can you swim?>',\n",
              " 'Can you swim?>',\n",
              " 'Can you walk?>',\n",
              " 'Can you walk?>',\n",
              " 'Check it out!>',\n",
              " 'Check it out!>',\n",
              " 'Come at once.>',\n",
              " 'Come back in.>',\n",
              " 'Come help me.>',\n",
              " 'Come help me.>',\n",
              " 'Come join us.>',\n",
              " 'Come join us.>',\n",
              " 'Come join us.>',\n",
              " 'Come join us.>',\n",
              " 'Come quickly!>',\n",
              " 'Come quickly!>',\n",
              " 'Come quickly!>',\n",
              " 'Come quickly!>',\n",
              " 'Come quickly.>',\n",
              " 'Come quickly.>',\n",
              " 'Come up here.>',\n",
              " 'Come up here.>',\n",
              " 'Come with me.>',\n",
              " 'Come with me.>',\n",
              " 'Come with me.>',\n",
              " 'Come with us.>',\n",
              " 'Cool it down.>',\n",
              " 'Could we sit?>',\n",
              " 'Cover for me.>',\n",
              " 'Cut that out!>',\n",
              " 'Cut that out!>',\n",
              " 'Cut that out!>',\n",
              " 'Cut that out!>',\n",
              " 'Did Tom call?>',\n",
              " 'Did Tom fall?>',\n",
              " 'Did Tom stay?>',\n",
              " 'Did Tom swim?>',\n",
              " 'Did you sign?>',\n",
              " 'Did you vote?>',\n",
              " 'Did you vote?>',\n",
              " 'Do I look OK?>',\n",
              " 'Do you agree?>',\n",
              " 'Do you agree?>',\n",
              " 'Do you agree?>',\n",
              " 'Do you drink?>',\n",
              " 'Do you drink?>',\n",
              " 'Do you smoke?>',\n",
              " 'Do you smoke?>',\n",
              " 'Do you smoke?>',\n",
              " 'Do you smoke?>',\n",
              " 'Do you smoke?>',\n",
              " 'Do your best!>',\n",
              " 'Do your best.>',\n",
              " 'Does it hurt?>',\n",
              " 'Does it hurt?>',\n",
              " 'Does it work?>',\n",
              " 'Does it work?>',\n",
              " \"Don't ask me.>\",\n",
              " \"Don't be sad.>\",\n",
              " \"Don't be sad.>\",\n",
              " \"Don't be shy.>\",\n",
              " \"Don't bother.>\",\n",
              " \"Don't bother.>\",\n",
              " \"Don't forget.>\",\n",
              " \"Don't get up.>\",\n",
              " \"Don't kid me!>\",\n",
              " \"Don't kid me!>\",\n",
              " \"Don't kid me!>\",\n",
              " \"Don't kid me!>\",\n",
              " \"Don't litter!>\",\n",
              " \"Don't ramble.>\",\n",
              " \"Don't ramble.>\",\n",
              " \"Don't resist.>\",\n",
              " 'Drive safely.>',\n",
              " 'Drive safely.>',\n",
              " 'Drop the gun.>',\n",
              " 'Drop the gun.>',\n",
              " 'Easy does it.>',\n",
              " 'Easy does it.>',\n",
              " 'Find the cat.>',\n",
              " 'Find the cat.>',\n",
              " 'Fish, please.>',\n",
              " 'Get a doctor.>',\n",
              " 'Get a doctor.>',\n",
              " 'Get my rifle.>',\n",
              " 'Get my rifle.>',\n",
              " 'Get my rifle.>',\n",
              " 'Get my rifle.>',\n",
              " 'Ghosts exist.>',\n",
              " 'Go to school.>',\n",
              " 'Go to school.>',\n",
              " 'Good for you.>',\n",
              " 'Good for you.>',\n",
              " 'Grab my hand.>',\n",
              " 'Grab my hand.>',\n",
              " 'Hand it over.>',\n",
              " 'Hand it over.>',\n",
              " 'Have a donut.>',\n",
              " 'Have a donut.>',\n",
              " 'Have a drink.>',\n",
              " 'Have a drink.>',\n",
              " 'Have a drink.>',\n",
              " 'Have a drink.>',\n",
              " 'Have a taste.>',\n",
              " 'Have a taste.>',\n",
              " 'Have another.>',\n",
              " 'He avoids me.>',\n",
              " 'He could die.>',\n",
              " 'He denied it.>',\n",
              " 'He denied it.>',\n",
              " 'He denied it.>',\n",
              " 'He denied it.>',\n",
              " 'He dozed off.>',\n",
              " 'He dumped me.>',\n",
              " 'He dumped me.>',\n",
              " 'He got angry.>',\n",
              " 'He got angry.>',\n",
              " 'He had a dog.>',\n",
              " 'He has a car.>',\n",
              " 'He has money.>',\n",
              " 'He helps her.>',\n",
              " 'He is a poet.>',\n",
              " 'He is a poet.>',\n",
              " 'He is asleep.>',\n",
              " 'He is cranky.>',\n",
              " 'He is eating.>',\n",
              " 'He is heroic.>',\n",
              " 'He is not in.>',\n",
              " 'He is not in.>',\n",
              " 'He kicked it.>',\n",
              " 'He let me go.>',\n",
              " 'He let me go.>',\n",
              " 'He let me go.>',\n",
              " 'He let me go.>',\n",
              " 'He let me go.>',\n",
              " 'He let me go.>',\n",
              " 'He let us go.>',\n",
              " 'He let us go.>',\n",
              " 'He let us go.>',\n",
              " 'He let us go.>',\n",
              " 'He let us go.>',\n",
              " 'He let us go.>',\n",
              " 'He likes tea.>',\n",
              " 'He lost face.>',\n",
              " 'He loves her.>',\n",
              " 'He mocked me.>',\n",
              " 'He needs you.>',\n",
              " 'He needs you.>',\n",
              " 'He shall die.>',\n",
              " 'He wants one.>',\n",
              " 'He wants one.>',\n",
              " 'He was alone.>',\n",
              " 'He was brave.>',\n",
              " 'He was brave.>',\n",
              " 'He was great.>',\n",
              " 'He was lucky.>',\n",
              " 'He was naive.>',\n",
              " 'He was naive.>',\n",
              " 'He was wrong.>',\n",
              " 'He was wrong.>',\n",
              " 'He was wrong.>',\n",
              " 'He will come.>',\n",
              " 'He will come.>',\n",
              " 'He will wait.>',\n",
              " \"He's English.>\",\n",
              " \"He's a bigot.>\",\n",
              " \"He's a bigot.>\",\n",
              " \"He's a bigot.>\",\n",
              " \"He's a bigot.>\",\n",
              " \"He's in pain.>\",\n",
              " \"He's married.>\",\n",
              " \"He's my hero.>\",\n",
              " \"He's out now.>\",\n",
              " \"He's so cute.>\",\n",
              " \"He's so cute.>\",\n",
              " 'Hello, girls.>',\n",
              " 'Hey, wait up!>',\n",
              " 'How annoying!>',\n",
              " 'How did I do?>',\n",
              " 'How horrible!>',\n",
              " 'How romantic!>',\n",
              " 'I admire you.>',\n",
              " 'I admire you.>',\n",
              " 'I always win.>',\n",
              " 'I am Italian.>',\n",
              " 'I am ashamed.>',\n",
              " 'I am at home.>',\n",
              " 'I am curious.>',\n",
              " 'I am married.>',\n",
              " 'I am so sick.>',\n",
              " 'I am so sick.>',\n",
              " 'I am so sick.>',\n",
              " 'I am so sick.>',\n",
              " 'I am thirsty.>',\n",
              " 'I am working.>',\n",
              " 'I apologized.>',\n",
              " 'I ate apples.>',\n",
              " 'I ate caviar.>',\n",
              " 'I believe it.>',\n",
              " 'I believe it.>',\n",
              " 'I called him.>',\n",
              " 'I called you.>',\n",
              " 'I called you.>',\n",
              " 'I called you.>',\n",
              " 'I called you.>',\n",
              " 'I called you.>',\n",
              " 'I called you.>',\n",
              " 'I can fix it.>',\n",
              " 'I can fix it.>',\n",
              " 'I can manage.>',\n",
              " \"I can't help.>\",\n",
              " \"I can't move.>\",\n",
              " \"I can't sing.>\",\n",
              " \"I can't sing.>\",\n",
              " \"I can't swim.>\",\n",
              " \"I can't wait.>\",\n",
              " \"I can't wait.>\",\n",
              " 'I caught Tom.>',\n",
              " 'I could help.>',\n",
              " 'I could help.>',\n",
              " 'I could walk.>',\n",
              " 'I could walk.>',\n",
              " 'I cried, too.>',\n",
              " 'I cut myself.>',\n",
              " 'I cut myself.>',\n",
              " 'I cut myself.>',\n",
              " 'I deserve it.>',\n",
              " 'I did my job.>',\n",
              " 'I did my job.>',\n",
              " 'I did my job.>',\n",
              " 'I did see it.>',\n",
              " \"I didn't ask.>\",\n",
              " \"I didn't cry.>\",\n",
              " \"I didn't pay.>\",\n",
              " \"I didn't win.>\",\n",
              " \"I didn't win.>\",\n",
              " \"I don't bite.>\",\n",
              " \"I don't care.>\",\n",
              " \"I don't care.>\",\n",
              " \"I don't date.>\",\n",
              " \"I don't date.>\",\n",
              " \"I don't date.>\",\n",
              " \"I don't date.>\",\n",
              " \"I don't date.>\",\n",
              " \"I don't know.>\",\n",
              " \"I don't mind.>\",\n",
              " \"I don't mind.>\",\n",
              " 'I doubt that.>',\n",
              " 'I drank milk.>',\n",
              " 'I drink beer.>',\n",
              " 'I enjoyed it.>',\n",
              " 'I feel alive.>',\n",
              " 'I feel awful.>',\n",
              " 'I feel dizzy.>',\n",
              " 'I feel faint.>',\n",
              " 'I feel faint.>',\n",
              " 'I feel faint.>',\n",
              " 'I feel faint.>',\n",
              " 'I feel faint.>',\n",
              " 'I feel funny.>',\n",
              " 'I feel funny.>',\n",
              " 'I feel giddy.>',\n",
              " 'I feel giddy.>',\n",
              " 'I feel giddy.>',\n",
              " 'I feel giddy.>',\n",
              " 'I feel happy.>',\n",
              " 'I feel lucky.>',\n",
              " 'I feel ready.>',\n",
              " 'I feel ready.>',\n",
              " 'I feel silly.>',\n",
              " 'I feel young.>',\n",
              " 'I felt awful.>',\n",
              " 'I felt awful.>',\n",
              " 'I felt awful.>',\n",
              " 'I felt great.>',\n",
              " 'I felt great.>',\n",
              " 'I felt happy.>',\n",
              " 'I felt happy.>',\n",
              " 'I felt naked.>',\n",
              " 'I felt naked.>',\n",
              " 'I felt naked.>',\n",
              " 'I felt naked.>',\n",
              " 'I felt safer.>',\n",
              " 'I go jogging.>',\n",
              " 'I go to work.>',\n",
              " 'I go to work.>',\n",
              " 'I go to work.>',\n",
              " 'I got carded.>',\n",
              " 'I got caught.>',\n",
              " 'I got caught.>',\n",
              " 'I got caught.>',\n",
              " 'I got dumped.>',\n",
              " 'I got dumped.>',\n",
              " 'I got dumped.>',\n",
              " 'I got dumped.>',\n",
              " 'I got sleepy.>',\n",
              " 'I got soaked.>',\n",
              " 'I had doubts.>',\n",
              " 'I handled it.>',\n",
              " 'I handled it.>',\n",
              " 'I handled it.>',\n",
              " 'I handled it.>',\n",
              " 'I handled it.>',\n",
              " 'I hate beans.>',\n",
              " 'I hate flies.>',\n",
              " 'I hate liars.>',\n",
              " 'I have a car.>',\n",
              " 'I have a car.>',\n",
              " 'I have a cat.>',\n",
              " 'I have a cat.>',\n",
              " 'I have a dog.>',\n",
              " 'I have a pen.>',\n",
              " 'I have hives.>',\n",
              " 'I have needs.>',\n",
              " 'I have plans.>',\n",
              " 'I have proof.>',\n",
              " 'I have proof.>',\n",
              " 'I have to go.>',\n",
              " 'I have to go.>']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Acq_F0bUlua"
      },
      "source": [
        "I trained all day, but the performance is still poor. I'll figure out why later. Maybe the RNN is too simple? Let's see.\n",
        "\n",
        "The problem is that in order to train the model by minibatch, I have to add a lot of padding tokens into the training set. This hurts the performance of the model. As seen in the above example, when I tried to translate the English sentence 'closer look' into French, there are a lot of padding tokens (&&&), which is annoying.\n",
        "\n",
        "I think if I train the model with individual examples, then the problem could be relieved. However, the downside is that it could be time-consuming.\n",
        "\n",
        "Anyway, I will try to update another file that will use attention mechanism.\n",
        "\n",
        "See you in another Colab file\n",
        "\n",
        "see you in the next week?\n",
        "\n",
        "I have to take care the new baby in my family. so in the weekend, I didnot have the time to adjust my code, and train the model. I will try to do that in the next week. see you then.\n",
        "\n",
        "I know, this is a small project, I just want to write those projects to be more familiar with the NLP, which is helpful for me in my future phd study.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeg_uyoLvunJ"
      },
      "source": [
        "I finally found the where the problem.\n",
        "\n",
        "first I should not only use the final hidden state of the encoder. I should concate all the hidden state, and convert them into decoder.\n",
        "\n",
        "second for the decoder, for the prediction, the predicted character should be conditioned by the previous characters, the current state, and the state of the encoder.\n",
        "\n",
        "third, it is for the loss function. when I calcualte the loss, if encounter the padding, I should stop, because the error in the loss could cause the model to go at the wrong direction.\n",
        "\n",
        "okay, I will ask for more advices from chatGPT, continue this project.\n",
        "\n",
        "one more thing to mention is that, by doing the second step, I could easily add the attention machaism between the encoder and the decoder."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMkGXSkKSAVnJdXSkUTy2s",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}