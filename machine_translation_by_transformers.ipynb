{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archyyu/translation-from-RNN-to-transformer/blob/main/machine_translation_by_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ma80RtZJnLKK"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oMBvKgnEpZmH"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/archyyu/publicResource/main/eng-fra.txt\"\n",
        "response = requests.get(url)\n",
        "lines = response.text.split('\\n')\n",
        "en_lines = []\n",
        "fr_lines = []\n",
        "\n",
        "start_character = '<'\n",
        "end_character = '>'\n",
        "padding_character = '&'\n",
        "\n",
        "for i in range(20000,30000):\n",
        "  item = lines[i].split('\\t')\n",
        "  en_lines.append('<' + item[0] + '>')\n",
        "  fr_lines.append('<' + item[1] + '>')\n",
        "\n",
        "max_len_line_en = max([len(l) for l in en_lines])\n",
        "max_len_line_fr = max([len(l) for l in fr_lines])\n",
        "max_len_line_en = max_len_line_fr\n",
        "\n",
        "for i in range(len(en_lines)):\n",
        "  if (len(en_lines[i]) < max_len_line_en):\n",
        "    en_lines[i] = en_lines[i].ljust(max_len_line_en, padding_character)\n",
        "  if (len(fr_lines[i]) < max_len_line_fr):\n",
        "    fr_lines[i] = fr_lines[i].ljust(max_len_line_fr, padding_character)\n",
        "\n",
        "\n",
        "source_vocab = sorted(set(''.join(en_lines)))\n",
        "target_vocab = sorted(set(''.join(fr_lines)))\n",
        "\n",
        "source_vocab_size = len(set(''.join(source_vocab)))\n",
        "target_vocab_size = len(set(''.join(target_vocab)))\n",
        "\n",
        "source_char_to_ix = {ch: i for i, ch in enumerate(source_vocab)}\n",
        "source_ix_to_char = {i: ch for i, ch in enumerate(source_vocab)}\n",
        "\n",
        "target_char_to_ix = {ch: i for i, ch in enumerate(target_vocab)}\n",
        "target_ix_to_char = {i: ch for i, ch in enumerate(target_vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "embedding_dim = 64\n",
        "seq_length = 80\n",
        "learning_rate = 1e-1\n",
        "batch_size = 20\n",
        "num_heads = 4\n",
        "head_size = 12\n",
        "head_num = 4\n",
        "layer_num = 4\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "id": "gOwCNJcStMI2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def line_to_tensor(line):\n",
        "  result = []\n",
        "  line_ten = torch.tensor([source_char_to_ix[ch] for ch in test_line], dtype=torch.long).view(1, -1)\n",
        "  result.append(line_ten)\n",
        "  return torch.cat(result, dim=0)\n",
        "\n",
        "def target_line_to_tensor(line):\n",
        "  result = []\n",
        "  line_ten = torch.tensor([target_char_to_ix[ch] for ch in test_line], dtype=torch.long).view(1, -1)\n",
        "  result.append(line_ten)\n",
        "  return torch.cat(result, dim=0)\n",
        "\n",
        "en_data = []\n",
        "fr_data = []\n",
        "for i in range(len(en_lines)):\n",
        "  e = torch.tensor([source_char_to_ix[ch] for ch in en_lines[i]], dtype=torch.long).view(1, -1)\n",
        "  en_data.append(e)\n",
        "  f = torch.tensor([target_char_to_ix[ch] for ch in fr_lines[i]], dtype=torch.long).view(1, -1)\n",
        "  fr_data.append(f)\n",
        "\n",
        "en_data = torch.cat(en_data, dim=0)\n",
        "fr_data = torch.cat(fr_data, dim=0)"
      ],
      "metadata": {
        "id": "d3bzq7JxOzAh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionHead(nn.Module):\n",
        "  def __init__(self, embed_size, head_size):\n",
        "    super(AttentionHead, self).__init__()\n",
        "    self.C = embed_size\n",
        "    self.head_size = head_size\n",
        "    self.q = nn.Linear(self.C, head_size, bias=False)\n",
        "    self.k = nn.Linear(self.C, head_size, bias=False)\n",
        "    self.v = nn.Linear(self.C, head_size, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    B,T,C = x.shape\n",
        "    q = self.q(x)\n",
        "    k = self.k(x)\n",
        "    v = self.v(x)\n",
        "\n",
        "    wei = q @ k.transpose(-2, -1) * (self.head_size ** -0.5)\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "    out = wei @ v\n",
        "    return out\n",
        "\n",
        "class CrossAttentionHead(nn.Module):\n",
        "  def __init__(self, embed_size, head_size):\n",
        "    super(CrossAttentionHead, self).__init__()\n",
        "    self.C = embed_size\n",
        "    self.head_size = head_size\n",
        "    self.q = nn.Linear(self.C, head_size, bias=False)\n",
        "    self.k = nn.Linear(self.C, head_size, bias=False)\n",
        "    self.v = nn.Linear(self.C, head_size, bias=False)\n",
        "    self.register_buffer('tril',torch.tril(torch.ones(seq_length, seq_length)))\n",
        "\n",
        "  def forward(self, x, q):\n",
        "    B,T,C = q.shape\n",
        "    q = self.q(q)\n",
        "    k = self.k(x)\n",
        "    v = self.v(x)\n",
        "\n",
        "    wei = q @ k.transpose(-2, -1) * (self.head_size ** -0.5)\n",
        "    wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "    out = wei @ v\n",
        "    return out\n",
        "\n",
        "\n",
        "class EncoderMultiHeadAttention(nn.Module):\n",
        "  def __init__(self, num_heads, embedding_size, head_size):\n",
        "    super(EncoderMultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.heads = nn.ModuleList([\n",
        "        AttentionHead(embedding_size, head_size) for _ in range(num_heads)\n",
        "    ])\n",
        "\n",
        "    self.final_linear = nn.Linear(num_heads * head_size, embedding_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    head_outputs = [head(x) for head in self.heads]\n",
        "    concatenated_output = torch.cat(head_outputs, dim=-1)\n",
        "    final_output = self.final_linear(concatenated_output)\n",
        "    final_output = self.dropout(final_output)\n",
        "    return final_output\n",
        "\n",
        "class DecoderMultiHeadAttention(nn.Module):\n",
        "  def __init__(self, num_heads, embedding_size, head_size):\n",
        "    super(DecoderMultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.heads = nn.ModuleList([\n",
        "        CrossAttentionHead(embedding_size, head_size) for _ in range(num_heads)\n",
        "    ])\n",
        "\n",
        "    self.final_linear = nn.Linear(num_heads * head_size, embedding_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x, encoder_x):\n",
        "    #x, encoder_x if those two are same, then it is self-attention, else cross-attention\n",
        "    head_outputs = [head(x, encoder_x) for head in self.heads]\n",
        "    concatenated_output = torch.cat(head_outputs, dim=-1)\n",
        "    final_output = self.final_linear(concatenated_output)\n",
        "    final_output = self.dropout(final_output)\n",
        "    return final_output\n",
        "\n",
        "\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "  def __init__(self, embedding_size):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "      nn.Linear(embedding_size, 4 * embedding_size),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(4 * embedding_size, embedding_size),\n",
        "      nn.Dropout(dropout),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)\n",
        "\n",
        "class EncoderBlockAttention(nn.Module):\n",
        "  def __init__(self, num_heads, embedding_size, head_size):\n",
        "    super(EncoderBlockAttention, self).__init__()\n",
        "    self.multiheads = EncoderMultiHeadAttention(num_heads, embedding_size, head_size)\n",
        "    self.fw = FeedFoward(embedding_size)\n",
        "    self.norm1 = nn.LayerNorm(embedding_size)\n",
        "    self.norm2 = nn.LayerNorm(embedding_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    inter_result = x + self.multiheads(self.norm1(x))\n",
        "    final_output = x + self.fw(self.norm2(inter_result))\n",
        "    return final_output\n",
        "\n",
        "\n",
        "class DecoderBlockAttention(nn.Module):\n",
        "  def __init__(self, num_heads, embedding_size, head_size):\n",
        "    super(DecoderBlockAttention, self).__init__()\n",
        "    self.multiheads = DecoderMultiHeadAttention(num_heads, embedding_size, head_size)\n",
        "    self.fw = FeedFoward(embedding_size)\n",
        "    self.norm1 = nn.LayerNorm(embedding_size)\n",
        "    self.norm2 = nn.LayerNorm(embedding_size)\n",
        "\n",
        "  def forward(self, x, encoder_x):\n",
        "    inter_result = x + self.multiheads(self.norm1(x), encoder_x)\n",
        "    final_output = x + self.fw(self.norm2(inter_result))\n",
        "    return final_output"
      ],
      "metadata": {
        "id": "xbNvoYmstdmn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, num_heads, vocab_size, embedding_size, head_size):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.em = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.pos_encode = nn.Embedding(seq_length, embedding_size)\n",
        "    self.selfattentionblocks = nn.ModuleList([DecoderBlockAttention(num_heads, embedding_size, head_size) for _ in range(4)])\n",
        "    self.crossattentionblocks = nn.ModuleList([DecoderBlockAttention(num_heads, embedding_size, head_size) for _ in range(4)])\n",
        "    self.f_norm = nn.LayerNorm(embedding_size)\n",
        "    self.fw = nn.Linear(embedding_size, vocab_size, bias=False)\n",
        "\n",
        "  def forward(self, x, encoder_x):\n",
        "    B,T = x.shape\n",
        "    x_em = self.em(x)\n",
        "    p_em = self.pos_encode(torch.arange(T))\n",
        "    x = x_em + p_em\n",
        "    for block in self.selfattentionblocks:\n",
        "      x = block(x, encoder_x)\n",
        "    for block in self.crossattentionblocks:\n",
        "      x = block(x, encoder_x)\n",
        "    x = self.f_norm(x)\n",
        "    x = self.fw(x)\n",
        "    return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, num_heads, vocab_size, embedding_size, head_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.em = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.pos_encode = nn.Embedding(seq_length, embedding_size)\n",
        "    self.blocks = nn.ModuleList([EncoderBlockAttention(num_heads, embedding_size, head_size) for _ in range(4)])\n",
        "    self.f_norm = nn.LayerNorm(embedding_size)\n",
        "    self.fw = nn.LayerNorm(embedding_size, vocab_size, bias=False)\n",
        "  def forward(self, x):\n",
        "    B,T = x.shape\n",
        "    x_em = self.em(x)\n",
        "    p_em = self.pos_encode(torch.arange(T))\n",
        "    x = x_em + p_em\n",
        "    for block in self.blocks:\n",
        "      x = block(x)\n",
        "    x = self.f_norm(x)\n",
        "    x = self.fw(x)\n",
        "    return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "  def __init__(self, num_heads, embed_size, input_vocab_size, target_vocab_size, source_seq_length, target_seq_length, head_size):\n",
        "    super(Transformer, self).__init__()\n",
        "    self.encoder = Encoder(num_heads, input_vocab_size, embed_size, head_size)\n",
        "    self.decoder = Decoder(num_heads, target_vocab_size, embed_size, head_size)\n",
        "\n",
        "  def forward(self, encoder_input, decoder_input):\n",
        "    encoder_output = self.encoder(encoder_input)\n",
        "    decoder_output = self.decoder(decoder_input, encoder_output)\n",
        "    return decoder_output"
      ],
      "metadata": {
        "id": "wbaEJaXpaHC4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "z5ONskhX-hQK"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "model = Transformer(num_heads, embedding_dim, source_vocab_size, target_vocab_size, max_len_line_en, max_len_line_fr, head_size)\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "NRjINVa0-ZbW",
        "outputId": "4dd6be6b-dd1b-4028-e782-57897d887f94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p 0, Loss: 4.861046314239502\n",
            "p 500, Loss: 1.9869235754013062\n",
            "p 1000, Loss: 1.2868788242340088\n",
            "p 1500, Loss: 1.2082597017288208\n",
            "p 2000, Loss: 1.5616120100021362\n",
            "p 2500, Loss: 1.3507484197616577\n",
            "p 3000, Loss: 1.0626707077026367\n",
            "p 3500, Loss: 0.6152390837669373\n",
            "p 4000, Loss: 0.04362526163458824\n",
            "p 4500, Loss: 0.03119976632297039\n",
            "p 5000, Loss: 0.05766305327415466\n",
            "p 5500, Loss: 0.051149796694517136\n",
            "p 6000, Loss: 0.008226211182773113\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-70e583126c97>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#training\n",
        "import torch.optim as optim\n",
        "\n",
        "num_epochs = 30\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "  for p in range(0,len(en_data) - batch_size - 1,batch_size):\n",
        "\n",
        "    source_batch = en_data[p:p+batch_size]\n",
        "    target_batch = fr_data[p:p+batch_size]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(source_batch, target_batch)\n",
        "\n",
        "    B,T,C = output.shape\n",
        "\n",
        "    # Compute the loss with the padding mask\n",
        "    loss = criterion(output.view(B*T, -1), target_batch.view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    for param in model.parameters():\n",
        "      if param.grad is not None:\n",
        "        param.grad.data.clamp_(-5, 5)\n",
        "    optimizer.step()\n",
        "\n",
        "    if p%500 == 0:\n",
        "      # Print or log the training loss for each epoch\n",
        "      print(f'p {p}, Loss: {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpgZG9toDSdb",
        "outputId": "9ebb754b-a0cb-4c6b-9b8a-92e3bc52784b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "&eere armed>&\n"
          ]
        }
      ],
      "source": [
        "test_line = \"We're armed>&\"\n",
        "\n",
        "input = line_to_tensor(test_line)\n",
        "\n",
        "outputs = model(input,target_line_to_tensor('<'))\n",
        "outputs = outputs.squeeze(0)\n",
        "\n",
        "softmax_probs = F.softmax(outputs, dim=-1)\n",
        "max_indices = torch.argmax(softmax_probs, dim=-1)\n",
        "\n",
        "result = []\n",
        "for i in range(max_indices.size(0)):\n",
        "  result.append(target_ix_to_char[max_indices[i].item()])\n",
        "\n",
        "\n",
        "print(''.join(result))\n",
        "\n",
        "# outputs = model(input,1)\n",
        "# result = []\n",
        "# for i in range(outputs.shape[0]):\n",
        "\n",
        "#   p = nn.functional.softmax(outputs[i], dim=-1).detach().numpy().ravel()\n",
        "#   ix = np.random.choice(range(target_vocab_size), p=p)\n",
        "\n",
        "#   result.append(target_ix_to_char[ix])\n",
        "\n",
        "# print(''.join(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is about the Chinese New Year\n",
        "So will stop that repo contemparaly\n",
        "\n",
        "will continue after the festival"
      ],
      "metadata": {
        "id": "q74b4XmRx-jx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj3NQ9XgBDuJGVRoqo9j39",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}