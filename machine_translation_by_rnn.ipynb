{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archyyu/translation-from-RNN-to-transformer/blob/main/machine_translation_by_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAzMVzsKlJlV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dKvwvE3qUB3q"
      },
      "outputs": [],
      "source": [
        "hidden_size = 100\n",
        "embedding_dim = 30\n",
        "learning_rate = 0.001\n",
        "batch_size = 50\n",
        "beam_width = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "pgaJy39hUt2C"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/archyyu/publicResource/main/eng-fra.txt\"\n",
        "response = requests.get(url)\n",
        "lines = response.text.split('\\n')\n",
        "en_lines = []\n",
        "fr_lines = []\n",
        "\n",
        "start_character = '<'\n",
        "end_character = '>'\n",
        "padding_character = '&'\n",
        "\n",
        "for i in range(20000,30000):\n",
        "  item = lines[i].split('\\t')\n",
        "  en_lines.append('<' + item[0] + '>')\n",
        "  fr_lines.append(item[1] + '>')\n",
        "\n",
        "max_len_line_en = max([len(l) for l in en_lines])\n",
        "max_len_line_fr = max([len(l) for l in fr_lines])\n",
        "\n",
        "for i in range(len(en_lines)):\n",
        "  if (len(en_lines[i]) < max_len_line_en):\n",
        "    en_lines[i] = en_lines[i].ljust(max_len_line_en, padding_character)\n",
        "  if (len(fr_lines[i]) < max_len_line_fr):\n",
        "    fr_lines[i] = fr_lines[i].ljust(max_len_line_fr, padding_character)\n",
        "\n",
        "\n",
        "source_vocab = sorted(set(''.join(en_lines)))\n",
        "target_vocab = sorted(set(''.join(fr_lines)))\n",
        "target_vocab.append('<')\n",
        "\n",
        "source_vocab_size = len(set(''.join(source_vocab)))\n",
        "target_vocab_size = len(set(''.join(target_vocab)))\n",
        "\n",
        "source_char_to_ix = {ch: i for i, ch in enumerate(source_vocab)}\n",
        "source_ix_to_char = {i: ch for i, ch in enumerate(source_vocab)}\n",
        "\n",
        "target_char_to_ix = {ch: i for i, ch in enumerate(target_vocab)}\n",
        "target_ix_to_char = {i: ch for i, ch in enumerate(target_vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR4jcQbVz6oH",
        "outputId": "840b2052-085f-461b-a10f-ccb744cfb7bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "execution_count": 298,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "GUfLKgxoU7j3"
      },
      "outputs": [],
      "source": [
        "def line_to_tensor(line):\n",
        "  result = []\n",
        "  line_ten = torch.tensor([source_char_to_ix[ch] for ch in test_line], dtype=torch.long).view(1, -1)\n",
        "  result.append(line_ten)\n",
        "  return torch.cat(result, dim=0)\n",
        "\n",
        "def target_line_to_tensor(line):\n",
        "  result = []\n",
        "  line_ten = torch.tensor([target_char_to_ix[ch] for ch in test_line], dtype=torch.long).view(1, -1)\n",
        "  result.append(line_ten)\n",
        "  return torch.cat(result, dim=0)\n",
        "\n",
        "en_data = []\n",
        "fr_data = []\n",
        "for i in range(len(en_lines)):\n",
        "  e = torch.tensor([source_char_to_ix[ch] for ch in en_lines[i]], dtype=torch.long).view(1, -1)\n",
        "  en_data.append(e)\n",
        "  f = torch.tensor([target_char_to_ix[ch] for ch in fr_lines[i]], dtype=torch.long).view(1, -1)\n",
        "  fr_data.append(f)\n",
        "\n",
        "en_data = torch.cat(en_data, dim=0)\n",
        "fr_data = torch.cat(fr_data, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "_aiwNJdMpOvb"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.i2h = nn.Linear(embedding_dim, hidden_size, bias=False)\n",
        "    self.h2h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "    self.hb2 = nn.Parameter(torch.zeros(1, hidden_size))\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = torch.zeros(1, self.hidden_size)\n",
        "    for i in range(x.shape[1]):\n",
        "      t = self.embedding(x[:,i])\n",
        "      h = torch.tanh(self.i2h(t) + self.h2h(h) + self.hb2)\n",
        "    return h\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.embedding = nn.Embedding(vocab_size, self.embedding_dim)\n",
        "    self.i2h = nn.Linear(self.embedding_dim, self.hidden_size, bias=False)\n",
        "    self.h2h = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "    self.h2o = nn.Linear(self.hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    self.hb2 = nn.Parameter(torch.zeros(1, self.hidden_size))\n",
        "    self.ob = nn.Parameter(torch.zeros(1, vocab_size))\n",
        "\n",
        "  def forward(self, h, batch_size):\n",
        "\n",
        "    # if x is None:\n",
        "    x = torch.tensor([target_char_to_ix[start_character] for _ in range(batch_size)],dtype=torch.long)\n",
        "    output = []\n",
        "    for i in range(max_len_line_fr):\n",
        "      t = self.embedding(x)\n",
        "      h = torch.tanh(self.i2h(t) + self.h2h(h) + self.hb2)\n",
        "      y = self.h2o(h) + self.ob\n",
        "      p = nn.functional.softmax(y, dim=1)\n",
        "      ix = torch.argmax(p, dim=-1)\n",
        "      x = ix\n",
        "      output.append(y)\n",
        "    return torch.stack(output, dim=0)\n",
        "\n",
        "  def beam_search(self, h):\n",
        "    \"\"\"\n",
        "    Perform beam search to generate sequences.\n",
        "    \"\"\"\n",
        "    beams = [(torch.tensor([target_char_to_ix[start_character]], dtype=torch.long), 1.0)]\n",
        "\n",
        "\n",
        "    for i in range(max_len_line_fr):\n",
        "      new_beams = []\n",
        "\n",
        "      for seq, score in beams:\n",
        "        x = seq[-1].view(1, -1)  # Take the last predicted token\n",
        "\n",
        "        t = self.embedding(x)\n",
        "        h = torch.tanh(self.i2h(t) + self.h2h(h) + self.hb2)\n",
        "        y = self.h2o(h) + self.ob\n",
        "        p = F.softmax(y, dim=-1)\n",
        "        top_probs, top_ix = torch.topk(p, beam_width, dim=-1)\n",
        "\n",
        "        for prob, token_ix in zip(top_probs[0][0], top_ix[0][0]):\n",
        "          new_seq = torch.cat((seq, torch.tensor([token_ix], dtype=torch.long)), dim=0)\n",
        "          new_beams.append((new_seq, score * prob.item()))\n",
        "\n",
        "      beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "\n",
        "    return beams\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, source_vocab_size, target_vocab_size, embedding_dim, hidden_size):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_size = hidden_size\n",
        "    self.encoder = Encoder(source_vocab_size, self.embedding_dim, self.hidden_size)\n",
        "    self.decoder = Decoder(target_vocab_size, self.embedding_dim, self.hidden_size)\n",
        "  def forward(self, source, batch_size):\n",
        "    hidden_state = self.encoder(source)\n",
        "    output = self.decoder(hidden_state, batch_size)\n",
        "    return output\n",
        "\n",
        "  def translate(self, source):\n",
        "    hidden_state = self.encoder(source)\n",
        "    beams = self.decoder.beam_search(hidden_state)\n",
        "    return beams\n",
        "\n",
        "\n",
        "# Define your model, loss function, and optimizer\n",
        "model = Seq2Seq(source_vocab_size, target_vocab_size, embedding_dim, hidden_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1HwqI27qRs9_",
        "outputId": "a1aac44b-7ab9-46f7-cbc4-87352ef98439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p 0, Loss: 1.9107469320297241\n",
            "p 100, Loss: 1.7525817155838013\n",
            "p 200, Loss: 1.963807225227356\n",
            "p 300, Loss: 1.8432202339172363\n",
            "p 400, Loss: 1.8197369575500488\n",
            "p 500, Loss: 1.9237337112426758\n",
            "p 600, Loss: 2.0000388622283936\n",
            "p 700, Loss: 1.980014681816101\n",
            "p 800, Loss: 1.8810944557189941\n",
            "p 900, Loss: 2.054216146469116\n",
            "p 1000, Loss: 1.8385647535324097\n",
            "p 1100, Loss: 1.6707831621170044\n",
            "p 1200, Loss: 1.9431257247924805\n",
            "p 1300, Loss: 1.7543889284133911\n",
            "p 1400, Loss: 1.8599927425384521\n",
            "p 1500, Loss: 1.8338054418563843\n",
            "p 1600, Loss: 2.081207752227783\n",
            "p 1700, Loss: 2.0136971473693848\n",
            "p 1800, Loss: 1.9742344617843628\n",
            "p 1900, Loss: 1.7932943105697632\n",
            "p 2000, Loss: 2.209684371948242\n",
            "p 2100, Loss: 1.912713646888733\n",
            "p 2200, Loss: 1.8072633743286133\n",
            "p 2300, Loss: 1.7550612688064575\n",
            "p 2400, Loss: 1.7997758388519287\n",
            "p 2500, Loss: 2.0657882690429688\n",
            "p 2600, Loss: 2.0518338680267334\n",
            "p 2700, Loss: 2.079054355621338\n",
            "p 2800, Loss: 1.940521240234375\n",
            "p 2900, Loss: 1.8966559171676636\n",
            "p 3000, Loss: 1.8518297672271729\n",
            "p 3100, Loss: 1.8585247993469238\n",
            "p 3200, Loss: 1.858514428138733\n",
            "p 3300, Loss: 1.85824716091156\n",
            "p 3400, Loss: 2.028543472290039\n",
            "p 3500, Loss: 2.0714926719665527\n",
            "p 3600, Loss: 1.8911818265914917\n",
            "p 3700, Loss: 2.0589418411254883\n",
            "p 3800, Loss: 2.106261730194092\n",
            "p 3900, Loss: 1.9562883377075195\n",
            "p 4000, Loss: 1.9248543977737427\n",
            "p 4100, Loss: 1.9933948516845703\n",
            "p 4200, Loss: 1.8329252004623413\n",
            "p 4300, Loss: 1.809194803237915\n",
            "p 4400, Loss: 1.93685781955719\n",
            "p 4500, Loss: 2.090524435043335\n",
            "p 4600, Loss: 1.8674358129501343\n",
            "p 4700, Loss: 1.8771170377731323\n",
            "p 4800, Loss: 1.9229031801223755\n",
            "p 4900, Loss: 1.9224332571029663\n",
            "p 5000, Loss: 2.0672261714935303\n",
            "p 5100, Loss: 1.920884370803833\n",
            "p 5200, Loss: 2.136819362640381\n",
            "p 5300, Loss: 1.8314100503921509\n",
            "p 5400, Loss: 1.8547383546829224\n",
            "p 5500, Loss: 1.830134630203247\n",
            "p 5600, Loss: 1.9181464910507202\n",
            "p 5700, Loss: 1.843021035194397\n",
            "p 5800, Loss: 1.8737473487854004\n",
            "p 5900, Loss: 2.1604056358337402\n",
            "p 6000, Loss: 2.122680902481079\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-f3fb6a58c658>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#training\n",
        "import torch.optim as optim\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "  for p in range(len(en_data) - batch_size - 1):\n",
        "\n",
        "    source_batch = en_data[p:p+batch_size]\n",
        "    target_batch = fr_data[p:p+batch_size]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    # encoder = Encoder(source_vocab_size, embedding_dim, hidden_size)\n",
        "    # output = encoder(source_batch)\n",
        "    output = model(source_batch, batch_size)\n",
        "\n",
        "    loss = criterion(output.view(-1, target_vocab_size), target_batch.view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    for param in model.parameters():\n",
        "      if param.grad is not None:\n",
        "        param.grad.data.clamp_(-5, 5)\n",
        "    optimizer.step()\n",
        "\n",
        "    if p%100 == 0:\n",
        "      # Print or log the training loss for each epoch\n",
        "      print(f'p {p}, Loss: {loss.item()}')\n",
        "\n",
        "    p += batch_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxVVtitSdL6t",
        "outputId": "dacc7a41-9fe1-49a4-c920-d4128c4d2487"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "< &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
            "<& &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n"
          ]
        }
      ],
      "source": [
        "test_line = \"closer look!>\"\n",
        "\n",
        "input = line_to_tensor(test_line)\n",
        "start = target_line_to_tensor(\"<\")\n",
        "\n",
        "\n",
        "outputs = model.translate(input)\n",
        "for tensor,p in outputs:\n",
        "  result = [target_ix_to_char[j.item()] for j in tensor]\n",
        "  print(''.join(result))\n",
        "\n",
        "# outputs = model(input,1)\n",
        "# result = []\n",
        "# for i in range(outputs.shape[0]):\n",
        "\n",
        "#   p = nn.functional.softmax(outputs[i], dim=-1).detach().numpy().ravel()\n",
        "#   ix = np.random.choice(range(target_vocab_size), p=p)\n",
        "\n",
        "#   result.append(target_ix_to_char[ix])\n",
        "\n",
        "# print(''.join(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Acq_F0bUlua"
      },
      "source": [
        "trained all day, but the performance is still poor, will figure out why later.\n",
        "may be the rnn is too simple?\n",
        "let see\n",
        "\n",
        "the problem is that, in order to train the model by minibatch, I have to add a lot of padding tokens into the training set. this will hurt the performance of the model.  as seen the above example, I tried to translate the english sentence closer look into france, there is alot of padding token &&&. which is anonying.\n",
        "\n",
        "I think If I train the model by individual example, then the problem could be relieved?\n",
        "\n",
        "but the problem is that coudl be time consuming.\n",
        "\n",
        "anyway, I will try to update an other file which will use attention machisum.\n",
        "\n",
        "see you in another colab file."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxxMDGSYXt13CeJkgxlms/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}