{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLO7HuB0nR+7Ytc8Ee8dL/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archyyu/translation-from-RNN-to-transformer/blob/main/machine_translation_by_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZAzMVzsKlJlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa8e731-3e22-47b1-9f63-5375549a19a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b229c224130>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 100\n",
        "embedding_dim = 20\n",
        "learning_rate = 1e-1\n",
        "batch_size = 50\n",
        "line_len = 30\n",
        "shuffle = True"
      ],
      "metadata": {
        "id": "dKvwvE3qUB3q"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/archyyu/publicResource/main/eng-fra.txt\"\n",
        "response = requests.get(url)\n",
        "lines = response.text.split('\\n')\n",
        "en_lines = []\n",
        "fr_lines = []\n",
        "\n",
        "start_character = '<'\n",
        "end_character = '>'\n",
        "padding_character = '&'\n",
        "\n",
        "for i in range(20000,40000):\n",
        "  item = lines[i].split('\\t')\n",
        "  en_lines.append('<' + item[0] + '>')\n",
        "  fr_lines.append('<' + item[1] + '>')\n",
        "\n",
        "max_len_line_en = max([len(l) for l in en_lines])\n",
        "max_len_line_fr = max([len(l) for l in fr_lines])\n",
        "\n",
        "for i in range(len(en_lines)):\n",
        "  if (len(en_lines[i]) < max_len_line_en):\n",
        "    en_lines[i] = en_lines[i].ljust(max_len_line_en, padding_character)\n",
        "  if (len(fr_lines[i]) < max_len_line_fr):\n",
        "    fr_lines[i] = fr_lines[i].ljust(max_len_line_fr, padding_character)\n",
        "\n",
        "\n",
        "source_vocab = set(''.join(en_lines))\n",
        "target_vocab = set(''.join(fr_lines))\n",
        "\n",
        "source_vocab_size = len(set(''.join(en_lines)))\n",
        "target_vocab_size = len(set(''.join(fr_lines)))\n",
        "\n",
        "source_char_to_ix = {ch: i for i, ch in enumerate(source_vocab)}\n",
        "source_ix_to_char = {i: ch for i, ch in enumerate(source_vocab)}\n",
        "\n",
        "target_char_to_ix = {ch: i for i, ch in enumerate(target_vocab)}\n",
        "target_ix_to_char = {i: ch for i, ch in enumerate(target_vocab)}"
      ],
      "metadata": {
        "id": "pgaJy39hUt2C"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_lines"
      ],
      "metadata": {
        "id": "LR4jcQbVz6oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def line_to_tensor(line):\n",
        "  result = []\n",
        "  line_ten = torch.tensor([source_char_to_ix[ch] for ch in test_line], dtype=torch.long).view(1, -1)\n",
        "  result.append(line_ten)\n",
        "  return torch.cat(result, dim=0)\n",
        "\n",
        "en_data = []\n",
        "fr_data = []\n",
        "for i in range(len(en_lines)):\n",
        "  e = torch.tensor([source_char_to_ix[ch] for ch in en_lines[i]], dtype=torch.long).view(1, -1)\n",
        "  en_data.append(e)\n",
        "  f = torch.tensor([target_char_to_ix[ch] for ch in fr_lines[i]], dtype=torch.long).view(1, -1)\n",
        "  fr_data.append(f)\n",
        "\n",
        "en_data = torch.cat(en_data, dim=0)\n",
        "fr_data = torch.cat(fr_data, dim=0)"
      ],
      "metadata": {
        "id": "GUfLKgxoU7j3"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UjKDo2obKEcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.i2h = nn.Linear(embedding_dim, hidden_size, bias=False)\n",
        "    self.h2h = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "    self.hb2 = nn.Parameter(torch.zeros(1, hidden_size))\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = torch.zeros((1, 1, self.hidden_size))\n",
        "    for i in range(x.shape[1]):\n",
        "      t = self.embedding(x[:,i])\n",
        "      h = torch.tanh(self.i2h(t) + self.h2h(h) + self.hb2)\n",
        "    return h\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.embedding = nn.Embedding(vocab_size, self.embedding_dim)\n",
        "    self.i2h = nn.Linear(self.embedding_dim, self.hidden_size, bias=False)\n",
        "    self.h2h = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
        "    self.h2o = nn.Linear(self.hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    self.hb2 = nn.Parameter(torch.zeros(1, self.hidden_size))\n",
        "    self.ob = nn.Parameter(torch.zeros(1, vocab_size))\n",
        "\n",
        "  def forward(self, x, h):\n",
        "    output = []\n",
        "    if x is None:\n",
        "      x = torch.tensor([[target_char_to_ix[start_character]]],dtype=torch.long)\n",
        "      for i in range(max_len_line_fr):\n",
        "        t = self.embedding(x)\n",
        "        h = torch.tanh(self.i2h(t) + self.h2h(h) + self.hb2)\n",
        "        y = self.h2o(h) + self.ob\n",
        "        p = nn.functional.softmax(y, dim=-1).detach().numpy().ravel()\n",
        "        ix = np.random.choice(range(y.shape[-1]), p=p)\n",
        "        # p = nn.functional.softmax(y, dim=-1)\n",
        "        # ix = torch.argmax(p).item()\n",
        "        if ix == target_char_to_ix[end_character]:\n",
        "          break\n",
        "        x = torch.tensor([[ix]], dtype=torch.long)\n",
        "        output.append(x)\n",
        "    else:\n",
        "      for i in range(x.shape[1]):\n",
        "        t = self.embedding(x[:,i])\n",
        "        h = torch.tanh(self.i2h(t) + self.h2h(h) + self.hb2)\n",
        "        y = self.h2o(h) + self.ob\n",
        "        output.append(y)\n",
        "    return output\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, source_vocab_size, target_vocab_size, embedding_dim, hidden_size):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_size = hidden_size\n",
        "    self.encoder = Encoder(source_vocab_size, self.embedding_dim, self.hidden_size)\n",
        "    self.decoder = Decoder(target_vocab_size, self.embedding_dim, self.hidden_size)\n",
        "  def forward(self, source, target):\n",
        "    hidden_state = self.encoder(source)\n",
        "    output = self.decoder(target, hidden_state)\n",
        "    return torch.cat(output, dim=0)\n",
        "\n",
        "# Define your model, loss function, and optimizer\n",
        "model = Seq2Seq(source_vocab_size, target_vocab_size, embedding_dim, hidden_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "_aiwNJdMpOvb"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training\n",
        "import torch.optim as optim\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "  for p in range(len(en_data) - batch_size - 1):\n",
        "\n",
        "    source_batch = en_data[p:p+batch_size]\n",
        "    target_batch = fr_data[p:p+batch_size]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(source_batch, target_batch)\n",
        "\n",
        "    loss = criterion(output.view(-1, target_vocab_size), target_batch.view(-1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if p%100 == 0:\n",
        "      # Print or log the training loss for each epoch\n",
        "      print(f'p {p}, Loss: {loss.item()}')\n",
        "\n",
        "    p += batch_size\n"
      ],
      "metadata": {
        "id": "1HwqI27qRs9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f7aebe-05cc-4290-9d7e-666801be58e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p 0, Loss: 3.251887321472168\n",
            "p 100, Loss: 2.9494118690490723\n",
            "p 200, Loss: 2.3397650718688965\n",
            "p 300, Loss: 2.3574161529541016\n",
            "p 400, Loss: 3.7748372554779053\n",
            "p 500, Loss: 5.193264007568359\n",
            "p 600, Loss: 2.66845965385437\n",
            "p 700, Loss: 2.1784262657165527\n",
            "p 800, Loss: 1.7893831729888916\n",
            "p 900, Loss: 1.9908764362335205\n",
            "p 1000, Loss: 2.730186939239502\n",
            "p 1100, Loss: 1.5725866556167603\n",
            "p 1200, Loss: 2.3945751190185547\n",
            "p 1300, Loss: 1.869131088256836\n",
            "p 1400, Loss: 1.784009575843811\n",
            "p 1500, Loss: 1.761156439781189\n",
            "p 1600, Loss: 8.86120319366455\n",
            "p 1700, Loss: 9.07079792022705\n",
            "p 1800, Loss: 6.381490707397461\n",
            "p 1900, Loss: 6.845973491668701\n",
            "p 2000, Loss: 4.543936729431152\n",
            "p 2100, Loss: 1.9161080121994019\n",
            "p 2200, Loss: 1.7431401014328003\n",
            "p 2300, Loss: 1.9001036882400513\n",
            "p 2400, Loss: 2.060920000076294\n",
            "p 2500, Loss: 2.929377317428589\n",
            "p 2600, Loss: 2.716270923614502\n",
            "p 2700, Loss: 2.191983461380005\n",
            "p 2800, Loss: 2.3377885818481445\n",
            "p 2900, Loss: 1.7934740781784058\n",
            "p 3000, Loss: 6.534148216247559\n",
            "p 3100, Loss: 8.764738082885742\n",
            "p 3200, Loss: 2.0602593421936035\n",
            "p 3300, Loss: 1.9500929117202759\n",
            "p 3400, Loss: 2.175291061401367\n",
            "p 3500, Loss: 1.9252489805221558\n",
            "p 3600, Loss: 1.745235800743103\n",
            "p 3700, Loss: 2.221911907196045\n",
            "p 3800, Loss: 1.9495371580123901\n",
            "p 3900, Loss: 2.125239610671997\n",
            "p 4000, Loss: 1.806018352508545\n",
            "p 4100, Loss: 2.2166950702667236\n",
            "p 4200, Loss: 2.0730693340301514\n",
            "p 4300, Loss: 3.0760648250579834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_line = \"<closer look!>\"\n",
        "\n",
        "input = line_to_tensor(test_line)\n",
        "output = model(input, None).view(-1)\n",
        "\n",
        "o = [target_ix_to_char[ch.item()] for ch in output]\n",
        "print(''.join(o))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxVVtitSdL6t",
        "outputId": "8083d6ef-2830-4927-e6c0-c1e9393e16e8"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "&&.&&&&&&&&&&& À&&&tÊt&&uhê&&&&&&l&&&&&&&& ÀV&aTr&&.i&&sTr&&&aU&&&&&&i&.V<\n"
          ]
        }
      ]
    }
  ]
}